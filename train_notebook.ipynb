{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN1QM5D3On7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "# Создание директорий под тренировочный и валидационный сеты\n",
        "root_dir = 'internship_data'\n",
        "maleCls = '/male'\n",
        "femaleCls = '/female'\n",
        "\n",
        "os.makedirs(root_dir +'/train' + maleCls)\n",
        "os.makedirs(root_dir +'/train' + femaleCls)\n",
        "os.makedirs(root_dir +'/val' + maleCls)\n",
        "os.makedirs(root_dir +'/val' + femaleCls)\n",
        "\n",
        "src1 = root_dir + maleCls\n",
        "src2 = root_dir + femaleCls\n",
        "\n",
        "#Получение списка с названиями всех изображений \n",
        "allFileNames1 = os.listdir(src1)\n",
        "allFileNames2 = os.listdir(src2)\n",
        "np.random.shuffle(allFileNames1)\n",
        "np.random.shuffle(allFileNames2)\n",
        "# Разбиение на 2 сета\n",
        "train_FileNames1, val_FileNames1 = np.split(np.array(allFileNames1), [int(len(allFileNames1)*0.9)])\n",
        "train_FileNames2, val_FileNames2 = np.split(np.array(allFileNames2), [int(len(allFileNames2)*0.9)])\n",
        "\n",
        "train_FileNames1 = [src1+'/'+ name for name in train_FileNames1.tolist()]\n",
        "val_FileNames1 = [src1+'/' + name for name in val_FileNames1.tolist()]\n",
        "train_FileNames2 = [src2+'/'+ name for name in train_FileNames2.tolist()]\n",
        "val_FileNames2 = [src2+'/' + name for name in val_FileNames2.tolist()]\n",
        "\n",
        "print('Total images: MaleCls: ',len(allFileNames1), ' FemaleCls: ', len(allFileNames2))\n",
        "print('Training: MaleCls: ',len(train_FileNames1), ' FemaleCls: ', len(train_FileNames2))\n",
        "print('Validation: MaleCls: ',len(val_FileNames1), ' FemaleCls: ', len(val_FileNames2))\n",
        "# Копирование изображений в папки\n",
        "for name in train_FileNames1:\n",
        "    shutil.copy(name, \"internship_data/train\"+maleCls)\n",
        "\n",
        "for name in val_FileNames1:\n",
        "    shutil.copy(name, \"internship_data/val\"+maleCls)\n",
        "\n",
        "for name in train_FileNames2:\n",
        "    shutil.copy(name, \"internship_data/train\"+femaleCls)\n",
        "\n",
        "for name in val_FileNames2:\n",
        "    shutil.copy(name, \"internship_data/val\"+femaleCls)\n",
        "\n",
        "# Создание csv файлов\n",
        "mtrain_names = ['male/' + name for name in os.listdir('internship_data/train/male/')]\n",
        "ftrain_names = ['female/' + name for name in os.listdir('internship_data/train/female/')]\n",
        "\n",
        "train_data_m = pd.DataFrame({'image_name': mtrain_names, 'class': np.zeros(len(mtrain_names), dtype=int)})\n",
        "train_data_f = pd.DataFrame({'image_name': ftrain_names, 'class': np.ones(len(ftrain_names), dtype=int)})\n",
        "train_data = pd.concat([train_data_m, train_data_f], ignore_index=True)\n",
        "train_data = train_data.sample(frac = 1)\n",
        "train_data.to_csv('train_data.csv', index = False)\n",
        "\n",
        "\n",
        "mval_names = ['male/' + name for name in os.listdir('internship_data/val/male/')]\n",
        "fval_names = ['female/' + name for name in os.listdir('internship_data/val/female/')]\n",
        "\n",
        "val_data_m = pd.DataFrame({'image_name': mval_names, 'class': np.zeros(len(mval_names), dtype=int)})\n",
        "val_data_f = pd.DataFrame({'image_name': fval_names, 'class': np.ones(len(fval_names), dtype=int)})\n",
        "val_data = pd.concat([val_data_m, val_data_f], ignore_index=True)\n",
        "val_data = val_data.sample(frac = 1)\n",
        "val_data.to_csv('val_data.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds2yB8ee3VHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms, utils\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from __future__ import print_function, division\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Класс для кастомного датасета\n",
        "class FaceRecognitionDataset(Dataset):\n",
        "  # Переопредленный конструктор класса\n",
        "  def __init__(self, csv_file, root_dir, transform=None):\n",
        "    self.source = pd.read_csv(csv_file)\n",
        "    self.root_dir = root_dir\n",
        "    self.transform = transform\n",
        "  # Метод получения размера\n",
        "  def __len__(self):\n",
        "    return(len(self.source))\n",
        "  # Метод получения очередного элемента датасета\n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "\n",
        "    img_name = os.path.join(self.root_dir, self.source.iloc[idx, 0])\n",
        "    image = io.imread(img_name)\n",
        "    clas = self.source.iloc[idx, 1]\n",
        "    sample = {'image': image, 'class': clas}\n",
        "\n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "\n",
        "    return sample\n",
        "\n",
        "# Класс для изменения размера изображения для кастомного датасета\n",
        "class Rescale(object):\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "      assert isinstance(output_size, (int, tuple))\n",
        "      self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "      image, clas = sample['image'], sample['class']\n",
        "\n",
        "      h, w = image.shape[:2]\n",
        "      if isinstance(self.output_size, int):\n",
        "        if h > w:\n",
        "          new_h, new_w = self.output_size * h / w, self.output_size\n",
        "        else:\n",
        "          new_h, new_w = self.output_size, self.output_size * w / h\n",
        "      else:\n",
        "        new_h, new_w = self.output_size\n",
        "\n",
        "      new_h, new_w = int(new_h), int(new_w)\n",
        "      img = transform.resize(image, (new_h, new_w))\n",
        "      return {'image': img, 'class': clas}\n",
        "\n",
        "\n",
        "# Класс для перевода изображения, хранящегося как numpy массив\n",
        "# в pytorch тензор, так как они имеют разные структуры размещения данных \n",
        "class ToTensor(object):\n",
        "\n",
        "  def __call__(self, sample):\n",
        "    image, clas = sample['image'], sample['class']\n",
        "    image = image.transpose((2, 0, 1))\n",
        "    return {'image': torch.from_numpy(image).float(), 'class': clas}\n",
        "\n",
        "# Класс для нормализации изображениий, так как используемые модели\n",
        "# были обучены на изображениях с указанными показателями нормализации\n",
        "class Normalize():\n",
        "\n",
        "  def __call__(self, sample):\n",
        "    image, clas = sample['image'], sample['class']\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "    image = transforms.functional.normalize(image, mean=mean, std=std)\n",
        "    return {'image': image, 'class': clas}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY-1VCOf65bz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Функция сохранения чекпоинтов модели\n",
        "def save_checkpoint(epoch, model, optimizer):\n",
        "\n",
        "    state = {'epoch': epoch,\n",
        "             'model': model,\n",
        "             'optimizer': optimizer}\n",
        "    filename = 'checkpoint_resnet50.pth.tar'\n",
        "    torch.save(state, filename)\n",
        "\n",
        "# Выбор девайса на котором будет производиться обучение,\n",
        "# выбирается GPU, если доступен, иначе CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Количество классов в датасете (пол: мужской, женский)\n",
        "num_classes = 2\n",
        "\n",
        "# Размер партии изображений для обучения\n",
        "batch_size = 16\n",
        "\n",
        "# Количесвто эпох для обучения\n",
        "num_epochs = 3\n",
        "\n",
        "# Флаг для использования feature extracting \n",
        "# (Переобучение параметров только измененных слоев нейросети). Если установлен False,\n",
        "# применяется finetune (переобучение параметров всех слоев нейросети)\n",
        "feature_extract = False\n",
        "\n",
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
        "    since = time.time()\n",
        "    # Список для хранения значений точности модели на валидационном наборе,\n",
        "    # подсчитанные после окончания каждой эпохи обучения\n",
        "    val_acc_history = []\n",
        "    # Переменная для выбора лучшей модели по итогам прохождения всех эпох\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    # Главный цикл обучения\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Каждая эпоха делится на 2 фазы: обучение и валидация\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # установка модели в режим обучения\n",
        "            else:\n",
        "                model.eval()   # установка модели в режим валидации\n",
        "            # Текущие потери\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Проход по всем изображениям, подаваемым загрузчиком партиями\n",
        "            for sample in dataloaders[phase]:\n",
        "                inputs = sample['image']\n",
        "                labels = sample['class']\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Обнуление градиентов перед каждым обратным распространением\n",
        "                # так как по умолчанию градиенты аккумулируются\n",
        "                optimizer.zero_grad()\n",
        " \n",
        "                # Сохранение истории только при обучении\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Получение предсказаний модели и расчет потерь\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # Обратное распространение и оптимизация при обучении\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Запись статистики\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # Сохранение весов модели после очередной эпохи обучения, если она точнее\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "            # Сохранение чекпоинта\n",
        "            save_checkpoint(epoch, model, optimizer)\n",
        "            # Очищение переменных\n",
        "            del preds, outputs, inputs, labels\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # Загрузка лучших весов\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awGJ7YX7FrIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Функция для feature extracting для выключения просчета градиентов у параметров, которые не будут обучаться\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "# Функция инициализации модели\n",
        "def initialize_model(num_classes, feature_extract, use_pretrained=True):\n",
        "  # в параметрах указывается использование предобученных весов\n",
        "  model_ft = models.resnet50(pretrained=use_pretrained)\n",
        "  set_parameter_requires_grad(model_ft, feature_extract)\n",
        "  num_ftrs = model_ft.fc.in_features\n",
        "  # Изменение последного решающего fc слоя, для того чтобы выход нейросети был равен указанному количеству классов\n",
        "  model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "  # Размер входных изображений\n",
        "  input_size = 224\n",
        "\n",
        "  return model_ft, input_size\n",
        "\n",
        "# Инициализация моедели\n",
        "model_ft, input_size = initialize_model(num_classes, feature_extract, use_pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPnp3h-ZMsfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Датасет для обучения\n",
        "train_dataset = FaceRecognitionDataset(csv_file='train_data.csv', root_dir='internship_data/train/',\n",
        "                                             transform=transforms.Compose([\n",
        "                                              Rescale((224, 224)),\n",
        "                                              ToTensor(),\n",
        "                                              Normalize()]))\n",
        "# Датасет для валидации\n",
        "val_dataset = FaceRecognitionDataset(csv_file='val_data.csv', root_dir='internship_data/val/',\n",
        "                                             transform=transforms.Compose([\n",
        "                                              Rescale((224, 224)),\n",
        "                                              ToTensor(),\n",
        "                                              Normalize()]))\n",
        "# Загрузчики данных\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "dataloaders_dict = {'train': train_loader, 'val': val_loader}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4rEy5UIR4Yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Переносим модель на выбранный девайс\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Параметры которые будут оптимизироваться\n",
        "params_to_update = model_ft.parameters()\n",
        "# Оптимизатор\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
        "\n",
        "# Функция подсчета потерь для валидации\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Запуск тренировки модели\n",
        "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}